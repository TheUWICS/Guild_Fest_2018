{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/keanu/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "from keras import backend as k\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import numpy as np\n",
    "from scipy import ndimage\n",
    "import sys\n",
    "import os\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load mnist dataset\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data() #everytime loading data won't be so easy :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   3  18  18  18 126 136\n",
      "  175  26 166 255 247 127   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  30  36  94 154 170 253 253 253 253 253\n",
      "  225 172 253 242 195  64   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0  49 238 253 253 253 253 253 253 253 253 251\n",
      "   93  82  82  56  39   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0  18 219 253 253 253 253 253 198 182 247 241\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  80 156 107 253 253 205  11   0  43 154\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0  14   1 154 253  90   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0 139 253 190   2   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0  11 190 253  70   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0  35 241 225 160 108   1\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0  81 240 253 253 119\n",
      "   25   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  45 186 253 253\n",
      "  150  27   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  16  93 252\n",
      "  253 187   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 249\n",
      "  253 249  64   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  46 130 183 253\n",
      "  253 207   2   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0  39 148 229 253 253 253\n",
      "  250 182   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0  24 114 221 253 253 253 253 201\n",
      "   78   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  23  66 213 253 253 253 253 198  81   2\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0  18 171 219 253 253 253 253 195  80   9   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0  55 172 226 253 253 253 253 244 133  11   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0 136 253 253 253 212 135 132  16   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]]\n"
     ]
    }
   ],
   "source": [
    "print(type(X_train))\n",
    "print(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVsAAAELCAYAAAB3QSUaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f063cf3d7b8>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#visualising first 9 data from training dataset\n",
    "fig = plt.figure()\n",
    "for i in range(9):\n",
    "  plt.subplot(3,3,i+1)\n",
    "  plt.tight_layout()\n",
    "  plt.imshow(X_train[i], cmap='gray', interpolation='none')\n",
    "  plt.title(\"Digit: {}\".format(y_train[i]))\n",
    "  plt.xticks([])\n",
    "  plt.yticks([])\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape (60000, 28, 28)\n",
      "y_train shape (60000,)\n",
      "X_test shape (10000, 28, 28)\n",
      "y_test shape (10000,)\n"
     ]
    }
   ],
   "source": [
    "# let's print the actual data shape before we reshape and normalize\n",
    "print(\"X_train shape\", X_train.shape)\n",
    "print(\"y_train shape\", y_train.shape)\n",
    "print(\"X_test shape\", X_test.shape)\n",
    "print(\"y_test shape\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#input image size 28*28\n",
    "img_rows , img_cols = 28, 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "#reshaping\n",
    "#this assumes our data format\n",
    "#For 3D data, \"channels_last\" assumes (conv_dim1, conv_dim2, conv_dim3, channels) while \n",
    "#\"channels_first\" assumes (channels, conv_dim1, conv_dim2, conv_dim3).\n",
    "if k.image_data_format() == 'channels_first':\n",
    "    X_train = X_train.reshape(X_train.shape[0], 1, img_rows, img_cols)\n",
    "    X_test = X_test.reshape(X_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    X_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, 1)\n",
    "    X_test = X_test.reshape(X_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "#more reshaping\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "print('X_train shape:', X_train.shape)\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.01176471]\n",
      "  [0.07058824]\n",
      "  [0.07058824]\n",
      "  [0.07058824]\n",
      "  [0.49411765]\n",
      "  [0.53333336]\n",
      "  [0.6862745 ]\n",
      "  [0.10196079]\n",
      "  [0.6509804 ]\n",
      "  [1.        ]\n",
      "  [0.96862745]\n",
      "  [0.49803922]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.11764706]\n",
      "  [0.14117648]\n",
      "  [0.36862746]\n",
      "  [0.6039216 ]\n",
      "  [0.6666667 ]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.88235295]\n",
      "  [0.6745098 ]\n",
      "  [0.99215686]\n",
      "  [0.9490196 ]\n",
      "  [0.7647059 ]\n",
      "  [0.2509804 ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.19215687]\n",
      "  [0.93333334]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.9843137 ]\n",
      "  [0.3647059 ]\n",
      "  [0.32156864]\n",
      "  [0.32156864]\n",
      "  [0.21960784]\n",
      "  [0.15294118]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.07058824]\n",
      "  [0.85882354]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.7764706 ]\n",
      "  [0.7137255 ]\n",
      "  [0.96862745]\n",
      "  [0.94509804]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.3137255 ]\n",
      "  [0.6117647 ]\n",
      "  [0.41960785]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.8039216 ]\n",
      "  [0.04313726]\n",
      "  [0.        ]\n",
      "  [0.16862746]\n",
      "  [0.6039216 ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.05490196]\n",
      "  [0.00392157]\n",
      "  [0.6039216 ]\n",
      "  [0.99215686]\n",
      "  [0.3529412 ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.54509807]\n",
      "  [0.99215686]\n",
      "  [0.74509805]\n",
      "  [0.00784314]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.04313726]\n",
      "  [0.74509805]\n",
      "  [0.99215686]\n",
      "  [0.27450982]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.13725491]\n",
      "  [0.94509804]\n",
      "  [0.88235295]\n",
      "  [0.627451  ]\n",
      "  [0.42352942]\n",
      "  [0.00392157]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.31764707]\n",
      "  [0.9411765 ]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.46666667]\n",
      "  [0.09803922]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.1764706 ]\n",
      "  [0.7294118 ]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.5882353 ]\n",
      "  [0.10588235]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.0627451 ]\n",
      "  [0.3647059 ]\n",
      "  [0.9882353 ]\n",
      "  [0.99215686]\n",
      "  [0.73333335]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.9764706 ]\n",
      "  [0.99215686]\n",
      "  [0.9764706 ]\n",
      "  [0.2509804 ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.18039216]\n",
      "  [0.50980395]\n",
      "  [0.7176471 ]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.8117647 ]\n",
      "  [0.00784314]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.15294118]\n",
      "  [0.5803922 ]\n",
      "  [0.8980392 ]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.98039216]\n",
      "  [0.7137255 ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.09411765]\n",
      "  [0.44705883]\n",
      "  [0.8666667 ]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.7882353 ]\n",
      "  [0.30588236]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.09019608]\n",
      "  [0.25882354]\n",
      "  [0.8352941 ]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.7764706 ]\n",
      "  [0.31764707]\n",
      "  [0.00784314]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.07058824]\n",
      "  [0.67058825]\n",
      "  [0.85882354]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.7647059 ]\n",
      "  [0.3137255 ]\n",
      "  [0.03529412]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.21568628]\n",
      "  [0.6745098 ]\n",
      "  [0.8862745 ]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.95686275]\n",
      "  [0.52156866]\n",
      "  [0.04313726]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.53333336]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.99215686]\n",
      "  [0.83137256]\n",
      "  [0.5294118 ]\n",
      "  [0.5176471 ]\n",
      "  [0.0627451 ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]\n",
      "\n",
      " [[0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]\n",
      "  [0.        ]]]\n"
     ]
    }
   ],
   "source": [
    "print(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]]\n",
      "\n",
      "\n",
      " [[[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]]\n",
      "\n",
      "\n",
      " [[[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]]\n",
      "\n",
      "\n",
      " [[[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]]\n",
      "\n",
      "\n",
      " [[[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]\n",
      "\n",
      "  [[0.]\n",
      "   [0.]\n",
      "   [0.]\n",
      "   ...\n",
      "   [0.]\n",
      "   [0.]\n",
      "   [0.]]]]\n"
     ]
    }
   ],
   "source": [
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=uint8), array([5923, 6742, 5958, 6131, 5842, 5421, 5918, 6265, 5851, 5949]))\n"
     ]
    }
   ],
   "source": [
    "print(np.unique(y_train, return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#set number of categories\n",
    "num_category = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert class vectors to binary class matrices# conver \n",
    "y_train = keras.utils.to_categorical(y_train, num_category)\n",
    "y_test = keras.utils.to_categorical(y_test, num_category)\n",
    "y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "##model building\n",
    "model = Sequential()\n",
    "#convolutional layer with rectified linear unit activation\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "#32 convolution filters used each of size 3x3\n",
    "#again\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "#64 convolution filters used each of size 3x3\n",
    "#choose the best features via pooling\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "#randomly turn neurons on and off to improve convergence\n",
    "model.add(Dropout(0.25))\n",
    "#flatten since too many dimensions, we only want a classification output\n",
    "model.add(Flatten())\n",
    "#fully connected to get all relevant data\n",
    "model.add(Dense(128, activation='relu'))\n",
    "#one more dropout for convergence' sake :) \n",
    "model.add(Dropout(0.5))\n",
    "#output a softmax to squash the matrix into output probabilities\n",
    "model.add(Dense(num_category, activation='softmax'))\n",
    "#Adaptive learning rate (adaDelta) is a popular form of gradient descent rivaled only by adam and adagrad\n",
    "#categorical ce since we have multiple classes (10) \n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/2\n",
      "60000/60000 [==============================] - 128s 2ms/step - loss: 0.2613 - acc: 0.9203 - val_loss: 0.0558 - val_acc: 0.9822\n",
      "Epoch 2/2\n",
      "60000/60000 [==============================] - 128s 2ms/step - loss: 0.0894 - acc: 0.9736 - val_loss: 0.0383 - val_acc: 0.9863\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "num_epoch = 2\n",
    "#model training\n",
    "model_log = model.fit(X_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=num_epoch,\n",
    "          verbose=1,\n",
    "          validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.03828812042782083\n",
      "Test accuracy: 0.9863\n"
     ]
    }
   ],
   "source": [
    "#how well did it do? \n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "#Save the model\n",
    "# serialize model to JSON\n",
    "model_digit_json = model.to_json()\n",
    "with open(\"model_digit.json\", \"w\") as json_file:\n",
    "    json_file.write(model_digit_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"model_digit.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getBestShift(img):\n",
    "    cy,cx = ndimage.measurements.center_of_mass(img)\n",
    "\n",
    "    rows,cols = img.shape\n",
    "    shiftx = np.round(cols/2.0-cx).astype(int)\n",
    "    shifty = np.round(rows/2.0-cy).astype(int)\n",
    "\n",
    "    return shiftx,shifty\n",
    "\n",
    "def shift(img,sx,sy):\n",
    "    rows,cols = img.shape\n",
    "    M = np.float32([[1,0,sx],[0,1,sy]])\n",
    "    shifted = cv2.warpAffine(img,M,(cols,rows))\n",
    "    return shifted\n",
    "\n",
    "def get_x_by_image(image,reverse=False):\n",
    "    # read the image\n",
    "    gray = cv2.imread(image, 0)\n",
    "\n",
    "    # rescale it\n",
    "    if reverse:\n",
    "        gray = cv2.resize(255 - gray, (28, 28))\n",
    "    else:\n",
    "        gray = cv2.resize(gray, (28, 28))\n",
    "    # better black and white version\n",
    "    (thresh, gray) = cv2.threshold(gray, 128, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)\n",
    "\n",
    "    while np.sum(gray[0]) == 0:\n",
    "        gray = gray[1:]\n",
    "\n",
    "    while np.sum(gray[:, 0]) == 0:\n",
    "        gray = np.delete(gray, 0, 1)\n",
    "\n",
    "    while np.sum(gray[-1]) == 0:\n",
    "        gray = gray[:-1]\n",
    "\n",
    "    while np.sum(gray[:, -1]) == 0:\n",
    "        gray = np.delete(gray, -1, 1)\n",
    "\n",
    "    rows, cols = gray.shape\n",
    "\n",
    "    if rows > cols:\n",
    "        factor = 20.0 / rows\n",
    "        rows = 20\n",
    "        cols = int(round(cols * factor))\n",
    "        # first cols than rows\n",
    "        gray = cv2.resize(gray, (cols, rows))\n",
    "    else:\n",
    "        factor = 20.0 / cols\n",
    "        cols = 20\n",
    "        rows = int(round(rows * factor))\n",
    "        # first cols than rows\n",
    "        gray = cv2.resize(gray, (cols, rows))\n",
    "\n",
    "    colsPadding = (int(math.ceil((28 - cols) / 2.0)), int(math.floor((28 - cols) / 2.0)))\n",
    "    rowsPadding = (int(math.ceil((28 - rows) / 2.0)), int(math.floor((28 - rows) / 2.0)))\n",
    "    gray = np.lib.pad(gray, (rowsPadding, colsPadding), 'constant')\n",
    "\n",
    "    shiftx, shifty = getBestShift(gray)\n",
    "    shifted = shift(gray, shiftx, shifty)\n",
    "    gray = shifted\n",
    "\n",
    "    \"\"\"\n",
    "    all images in the training set have an range from 0-1\n",
    "    and not from 0-255 so we divide our flatten images\n",
    "    (a one dimensional vector with our 784 pixels)\n",
    "    to use the same 0-1 based range\n",
    "    \"\"\"\n",
    "    flatten = gray.flatten() / 255.0\n",
    "    return flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gray = get_x_by_image('IMG_0865.JPG',reverse='False')\n",
    "#gray5 = get_x_by_image('IMG_0866.JPG',reverse='False')\n",
    "#gray6 = get_x_by_image('IMG_0858.JPG',reverse='False')\n",
    "gray7 = get_x_by_image('IMG_0816.JPG',reverse='False')\n",
    "#gray8 = get_x_by_image('IMG_0864.JPG',reverse='False')\n",
    "#print(gray)\n",
    "#gray1 = cv2.resize(gray, (28, 28))\n",
    "#gray = get_x_by_image('IMG_0816.JPG',reverse='False')\n",
    "#print(gray)\n",
    "#gray1 = cv2.resize(gray, (28, 28))\n",
    "#batch_x.append(gray1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#temp = (np.resize(gray,(img_rows, img_cols)))\n",
    "#temp2 = (np.resize(gray5,(img_rows, img_cols)))\n",
    "#temp3 = (np.resize(gray6,(img_rows, img_cols)))\n",
    "temp4 = (np.resize(gray7,(img_rows, img_cols)))\n",
    "#temp5 = (np.resize(gray8,(img_rows, img_cols)))\n",
    "kr = np.array([temp4])\n",
    "#print(kr[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#temp = np.resize(gray,(img_rows, img_cols))\n",
    "#np.resize(a,(2,4))\n",
    "#reshaping\n",
    "#this assumes our data format\n",
    "#For 3D data, \"channels_last\" assumes (conv_dim1, conv_dim2, conv_dim3, channels) while \n",
    "#\"channels_first\" assumes (channels, conv_dim1, conv_dim2, conv_dim3).\n",
    "if k.image_data_format() == 'channels_first':\n",
    "    kr = kr.reshape(kr.shape[0], 1, 28, 28)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    kr = kr.reshape(kr.shape[0], 28, 28, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "#more reshaping\n",
    "kr = kr.astype('float32')\n",
    "kr /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nlAAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f0639b33c18>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#print(x_test[0])\n",
    "\n",
    "digit = kr[0].reshape(28,28)\n",
    "#plt.subplot(221)\n",
    "plt.imshow(digit, cmap=plt.get_cmap('gray'))\n",
    "plt.savefig('img.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "print(kr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n"
     ]
    }
   ],
   "source": [
    "print(model.predict_classes(kr))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
